# M√âDIA-SCAN - Guide de D√©marrage Rapide

## Installation

### 1. Cr√©er un environnement virtuel

```bash
python -m venv venv

# Sur macOS/Linux:
source venv/bin/activate

# Sur Windows:
venv\Scripts\activate
```

### 2. Installer les d√©pendances

```bash
pip install -r requirements.txt

# T√©l√©charger le mod√®le fran√ßais pour spaCy
python -m spacy download fr_core_news_md
```

### 3. Initialiser la base de donn√©es

```bash
python -m database.db_manager
```

## Utilisation

### Option 1: Scraper UN m√©dia sp√©cifique

```bash
# Lefaso.net (20 pages par rubrique)
python -m scrapers.lefaso_scraper --max-pages 20

# FasoPresse (10 pages par cat√©gorie)
python -m scrapers.fasopresse_scraper --max-pages 10

# Sidwaya (10 pages par cat√©gorie)
python -m scrapers.sidwaya_scraper --max-pages 10

# L'AIB 
python -m scrapers.aib_scraper --max-pages 10

# L'observateur 
python -m scrapers.lobservateur_scraper --max-pages 10

# Burkina 24
python -m scrapers.burkina_24_scraper --max-pages 10

#Collecte training data
python collect_training_data.py --scrapers burkina24  --max-pages 10
```

### Option 2: Utiliser le script principal (RECOMMAND√â)

```bash
# 1. Scraper TOUS les m√©dias
python main.py --scrape --max-pages 20

# 2. Importer les donn√©es dans la base de donn√©es
python main.py --import

# 3. Afficher les statistiques
python main.py --stats

# 4. Tout faire en une seule commande
python main.py --all --max-pages 20
```

## Workflow pour le Hackathon

### Jour 1: Collecte de donn√©es (MODULE 1)

```bash
# Scraper les m√©dias (objectif: 100+ articles)
python main.py --scrape --max-pages 20

# Importer dans la BDD
python main.py --import

# V√©rifier les stats
python main.py --stats
```

**Objectif**: Obtenir au moins 100 articles de 5 m√©dias diff√©rents.

### Jour 2: Analyse (MODULES 2, 3, 4, 5)

√Ä d√©velopper:
- `analysis/theme_classifier.py` - Classification th√©matique (MODULE 2)
- `analysis/influence_scorer.py` - Calcul scores d'influence (MODULE 3)
- `analysis/sentiment_detector.py` - D√©tection contenus sensibles (MODULE 5)

### Jour 3: Dashboard (MODULE 6)

√Ä d√©velopper:
- `dashboard/app.py` - Dashboard Streamlit interactif

Lancer avec:
```bash
python main.py --dashboard
```

## Structure des Donn√©es

### Articles collect√©s (JSON)

Emplacement: `data/raw/*.json`

```json
{
  "id": "abc123",
  "media": "Lefaso.net",
  "titre": "Titre de l'article",
  "date": "2025-11-15",
  "url": "https://...",
  "contenu": "Contenu de l'article...",
  "engagement": {
    "likes": 0,
    "partages": 0,
    "commentaires": 5
  },
  "metadata": {
    "rubrique_name": "politique",
    "scraped_at": "2025-11-15T10:30:00"
  },
  "comments": [...]
}
```

### Base de donn√©es (SQLite)

Emplacement: `database/media_scan.db`

Tables:
- `medias` - Informations sur les m√©dias
- `articles` - Articles collect√©s
- `media_stats` - Statistiques quotidiennes
- `alerts` - Alertes de monitoring

## Commandes Utiles

### V√©rifier combien d'articles ont √©t√© collect√©s

```bash
python -c "import json; print(len(json.load(open('data/raw/lefaso_articles.json'))))"
```

### Acc√©der √† la base de donn√©es

```bash
sqlite3 database/media_scan.db
```

```sql
-- Compter les articles
SELECT COUNT(*) FROM articles;

-- Articles par m√©dia
SELECT m.nom, COUNT(a.id) as nb_articles
FROM medias m
LEFT JOIN articles a ON m.id = a.media_id
GROUP BY m.nom;

-- Top m√©dias par engagement
SELECT nom, engagement_total, score_influence, rang
FROM medias
ORDER BY rang;
```

## Conseils pour le Hackathon

1. **Jour 1 (24h)**: Focus sur la collecte
   - Tester chaque scraper individuellement
   - Viser 100+ articles minimum
   - V√©rifier la qualit√© des donn√©es

2. **Jour 2 (24h)**: Impl√©menter l'IA
   - Classification th√©matique avec CamemBERT
   - Calcul des scores d'influence
   - Bonus: D√©tection de toxicit√©

3. **Jour 3 (24h)**: Dashboard et d√©mo
   - Interface Streamlit
   - Visualisations avec Plotly
   - Export PDF/Excel
   - Pr√©parer la d√©mo

## D√©pannage

### Erreur lors du scraping

```bash
# V√©rifier la connexion internet
ping lefaso.net

# R√©duire le nombre de pages
python main.py --scrape --max-pages 5
```

### Base de donn√©es verrouill√©e

```bash
# Supprimer et recr√©er
rm database/media_scan.db
python -m database.db_manager
```

### D√©pendances manquantes

```bash
# R√©installer toutes les d√©pendances
pip install -r requirements.txt --upgrade
```

## Support

- Documentation compl√®te: `README.md`
- Configuration: `config/settings.py`
- Logs: V√©rifier la console pour les messages d'erreur

Bon courage pour le hackathon! üöÄ